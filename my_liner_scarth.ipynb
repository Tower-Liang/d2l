{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def sy_data(w,b,num_examples):\n",
    "    X=torch.randn(num_examples,len(w))\n",
    "    y=torch.matmul(X,w)+b\n",
    "    y+=torch.tensor(torch.randn(y.size())*0.01)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_iter(features, labels, batch_size):\n",
    "    num_examples=len(features)\n",
    "    indices=list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "        batch_indices=indices[i:min(num_examples,i+batch_size)]\n",
    "        yield features[batch_indices], labels[batch_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_work(X,w,b):\n",
    "    return torch.matmul(X,w)+b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat,y):\n",
    "    return (y_hat-y.reshape(y_hat.shape))**2/2\n",
    "\n",
    "def optimizer(lr,parms,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for parm in parms:\n",
    "            parm-=lr*parm.grad/batch_size\n",
    "            parm.grad.zero_()\n",
    "\n",
    "'''parm=parm-lr*parm.grad/batch_size是不行的，因为未能在原地修改parm的值，而是创建了一个新的tensor，\n",
    "所以需要用parm-=lr*parm.grad/batch_size\n",
    "不加with torch.no_grad()会报错，因为在计算parm-=lr*parm.grad/batch_size时，parm.grad会被清零，\n",
    "而parm.grad.zero_()是在with torch.no_grad()中执行的'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203344/2811244393.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y+=torch.tensor(torch.randn(y.size())*0.01)\n"
     ]
    }
   ],
   "source": [
    "# 生成数据\n",
    "true_w=torch.tensor([[2],[-3.4]])\n",
    "true_b=4.2\n",
    "features,labels=sy_data(true_w,true_b,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 8.899545669555664\n",
      "epoch 2 loss 4.971363067626953\n",
      "epoch 3 loss 2.7790470123291016\n",
      "epoch 4 loss 1.5548310279846191\n",
      "epoch 5 loss 0.870550274848938\n",
      "epoch 6 loss 0.48774683475494385\n",
      "epoch 7 loss 0.2735208570957184\n",
      "epoch 8 loss 0.15353119373321533\n",
      "epoch 9 loss 0.08626347035169601\n",
      "epoch 10 loss 0.04851175844669342\n",
      "epoch 11 loss 0.027311289682984352\n",
      "epoch 12 loss 0.01540087629109621\n",
      "epoch 13 loss 0.008698267862200737\n",
      "epoch 14 loss 0.004927608650177717\n",
      "epoch 15 loss 0.00280264881439507\n",
      "epoch 16 loss 0.0016056678723543882\n",
      "epoch 17 loss 0.000929593457840383\n",
      "epoch 18 loss 0.0005477332160808146\n",
      "epoch 19 loss 0.0003322855045553297\n",
      "epoch 20 loss 0.00021020641725044698\n"
     ]
    }
   ],
   "source": [
    "# 模型的训练\n",
    "batch_size=100\n",
    "w=torch.normal(0,0.01,size=(2,1),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "for epoch in range(20):\n",
    "    for X,y in data_iter(features,labels,batch_size):\n",
    "        y_hat=net_work(X,w,b)\n",
    "        l=squared_loss(y_hat,y)\n",
    "        l.sum().backward()\n",
    "        optimizer(0.03,[w,b],batch_size)\n",
    "    with torch.no_grad():\n",
    "        train_loss=squared_loss(net_work(features,w,b),labels)\n",
    "        print(f'epoch {epoch+1} loss {train_loss.sum()/len(features)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
